<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Fit Poisson GLM-PCA Model to Count Data — fit_glmpca_pois • fastglmpca</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Fit Poisson GLM-PCA Model to Count Data — fit_glmpca_pois"><meta property="og:description" content="Fit a Poisson GLM-PCA model by maximum-likelihood."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">fastglmpca</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1-106</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/stephenslab/fastglmpca" class="external-link">Source</a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Fit Poisson GLM-PCA Model to Count Data</h1>
    <small class="dont-index">Source: <a href="https://github.com/stephenslab/fastglmpca/blob/HEAD/R/fit.R" class="external-link"><code>R/fit.R</code></a>, <a href="https://github.com/stephenslab/fastglmpca/blob/HEAD/R/init.R" class="external-link"><code>R/init.R</code></a></small>
    <div class="hidden name"><code>fit_glmpca_pois.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Fit a Poisson GLM-PCA model by maximum-likelihood.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">fit_glmpca_pois</span><span class="op">(</span></span>
<span>  <span class="va">Y</span>,</span>
<span>  <span class="va">K</span>,</span>
<span>  fit0 <span class="op">=</span> <span class="fu">init_glmpca_pois</span><span class="op">(</span><span class="va">Y</span>, <span class="va">K</span><span class="op">)</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu">fit_glmpca_pois_control_default</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">init_glmpca_pois</span><span class="op">(</span></span>
<span>  <span class="va">Y</span>,</span>
<span>  <span class="va">K</span>,</span>
<span>  <span class="va">U</span>,</span>
<span>  <span class="va">V</span>,</span>
<span>  X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>,</span>
<span>  Z <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>,</span>
<span>  B <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>,</span>
<span>  W <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>,</span>
<span>  fixed_b_cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>,</span>
<span>  fixed_w_cols <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fl">0</span><span class="op">)</span>,</span>
<span>  col_size_factor <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  row_intercept <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>Y</dt>
<dd><p>The n x m matrix of counts; all entries of <code>Y</code> should
be non-negative. It can be a sparse matrix (class
<code>"dsparseMatrix"</code>) or dense matrix (class <code>"matrix"</code>).</p></dd>


<dt>K</dt>
<dd><p>Integer 1 or greater specifying the rank of the matrix
factorization. This should only be provided if the initial fit
(<code>fit0</code>) is not.</p></dd>


<dt>fit0</dt>
<dd><p>Initial model fit. It should be an object of class
“glmpca_fit_pois”, such as an output from
<code>init_glmpca_pois</code> or a previous call to
<code>fit_glmpca_pois</code>.</p></dd>


<dt>verbose</dt>
<dd><p>If <code>verbose = TRUE</code>, information about the
algorithm's progress is printed after each update.</p></dd>


<dt>control</dt>
<dd><p>List of control parameters to modify behavior of
the optimization algorithm; see “Details”.</p></dd>


<dt>U</dt>
<dd><p>An optional argument giving the initial estimate of the
loadings matrix. It should be an n x K matrix, where n is the
number of rows in the counts matrix <code>Y</code>, and K &gt; 0 is the rank
of the matrix factorization. When <code>U</code> and <code>V</code> are not
provided, input argument <code>K</code> should be specified instead.</p></dd>


<dt>V</dt>
<dd><p>An optional argument giving is the initial estimate of the
factors matrix. It should be a m x K matrix, where m is the number
of columns in the counts matrix <code>Y</code>, and K &gt; 0 is the rank of
the matrix factorization. When <code>U</code> and <code>V</code> are not
provided, input argument <code>K</code> should be specified instead.</p></dd>


<dt>X</dt>
<dd><p>Optional argument giving row covariates of the count
matrix <code>Y</code>. It should be an n x nx matrix, where nx is
the number of row covariates.</p></dd>


<dt>Z</dt>
<dd><p>Optional argument giving column covariates of the count
matrix <code>Y</code>. It should be an m x nz matrix, where nz is the
number of column covariates.</p></dd>


<dt>B</dt>
<dd><p>Optional argument giving the initial estimates for the
coefficients of the row covariates. It should be an m x nx matrix,
where nx is the number of row covariates.
This argument is ignored if X is not provided.</p></dd>


<dt>W</dt>
<dd><p>Optional argument giving the initial estimates for the
coefficients of the column covariates.  It should be an n x nz matrix,
where nz is the number of column covariates.
This argument is ignored if Z is not provided.</p></dd>


<dt>fixed_b_cols</dt>
<dd><p>Optional numeric vector specifying which
columns of <code>B</code> (if any) should be fixed during
optimization. This argument is ignored if X is not provided.</p></dd>


<dt>fixed_w_cols</dt>
<dd><p>Optional numeric vector specifying which
columns of <code>W</code> (if any) should be fixed during
optimization. This argument is ignored if Z is not provided.</p></dd>


<dt>col_size_factor</dt>
<dd><p>If <code>col_size_factor = TRUE</code>, add a
fixed factor accounting for average differences in Poisson rates
across columns of <code>Y</code>. Setting <code>col_size_factor = TRUE</code>
and <code>row_intercept = TRUE</code> is intended to replicate the
default behavior of <code>glmpca</code>.</p></dd>


<dt>row_intercept</dt>
<dd><p>If <code>row_intercept = TRUE</code>, add a factor
accounting for average differences in Poisson rates across rows of
<code>Y</code>. Setting <code>col_size_factor = TRUE</code> and
<code>row_intercept = TRUE</code> is intended to replicate the default
behavior of <code>glmpca</code>.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    

<p>An object capturing the state of the model fit. It contains
  estimates of \(U\), \(V\) and \(D\) (stored as matrices</p>
<p></p>
<p><code>U</code>, <code>V</code> and a vector of diagonal entries <code>d</code>,
  analogous to the <code><a href="https://rdrr.io/r/base/svd.html" class="external-link">svd</a></code> return value); the other
  parameters (\(X\), \(B\), \(Z\), \(W\)); the log-likelihood
  achieved (<code>loglik</code>); information about which columns of</p>
<p></p>
<p>\(B\) and \(W\) are fixed (<code>fixed_b_cols</code>,</p>
<p></p>
<p><code>fixed_w_cols</code>); and a data frame <code>progress</code> storing
  information about the algorithm's progress after each update.</p>
    </div>
    <div id="details">
    <h2>Details</h2>
    <p>In generalized principal component analysis (GLM-PCA)
based on a Poisson likelihood, the counts \(y_{ij}\) stored in an
\(n \times m\) matrix \(Y\) are modeled as $$y_{ij}
\sim Pois(\lambda_{ij}),$$ in which the logarithm of each rate
parameter \(\lambda_{ij}\) is defined as a linear combination of
rank-K matrices to be estimated from the data: $$\log
\lambda_{ij} = (UDV')_{ij},$$ where \(U\) and \(V\) are
orthogonal matrices of dimension \(n \times K\) and \(m
\times K\), respectively, and \(D\) is a diagonal \(K
\times K\) matrix in which the entries along its diagonal are
positive and decreasing. \(K\) is a tuning parameter specifying
the rank of the matrix factorization. This is the same as the
low-rank matrix decomposition underlying PCA (that is, the singular
value decomposition), but because we are not using a linear
(Gaussian) model, this is called “generalized PCA” or
“GLM PCA”.</p>
<p>To allow for additional components that may be fixed,
<code>fit_glmpca_pois</code> can also fit the more general model
$$\log \lambda_{ij} = (UDV' + XB' + WZ')_{ij},$$ in which
\(X\), \(Z\) are fixed matrices of dimension \(n \times
n_x\) and \(m \times n_z\), respectively, and
\(B\), \(W\) are matrices of dimension \(m \times n_x\) and \(n \times n_z\) to be estimated from the data.</p>
<p><code>fit_glmpca_pois</code> computes maximum-likelihood estimates (MLEs)
of \(U\), \(V\), \(D\), \(B\) and \(W\) satistifying the
orthogonality constraints for \(U\) and \(V\) and the
additional constraints on \(D\) that the entries are positive and
decreasing. This is accomplished by iteratively fitting a series of
Poisson GLMs, where each of these individual Poissons GLMs is fitted
using a fast “cyclic co-ordinate descent” (CCD) algorithm.</p>
<p>The <code>control</code> argument is a list in which any of the following
named components will override the default optimization algorithm
settings (as they are defined by
<code>fit_glmpca_pois_control_default</code>). Additional control
arguments not listed here can be used to control the behaviour of
<code><a href="https://rdrr.io/pkg/daarem/man/fpiter.html" class="external-link">fpiter</a></code> or <code><a href="https://rdrr.io/pkg/daarem/man/daarem.html" class="external-link">daarem</a></code>; see
the help accompanying these functions for details.</p>
<dl><dt><code>use_daarem</code></dt>
<dd><p>If <code>use_daarem = TRUE</code>, the updates
  are accelerated using DAAREM; see <code><a href="https://rdrr.io/pkg/daarem/man/daarem.html" class="external-link">daarem</a></code> for
  details.</p></dd>


<dt><code>tol</code></dt>
<dd><p>This is the value of the “tol” control
  argument for <code><a href="https://rdrr.io/pkg/daarem/man/fpiter.html" class="external-link">fpiter</a></code> or
  <code><a href="https://rdrr.io/pkg/daarem/man/daarem.html" class="external-link">daarem</a></code> that determines when to stop the
  optimization. In brief, the optimization stops when the change in
  the estimates or in the log-likelihood between two successive
  updates is less than “tol”.</p></dd>


<dt><code>maxiter</code></dt>
<dd><p>This is the value of the “maxiter”
  control argument for <code><a href="https://rdrr.io/pkg/daarem/man/fpiter.html" class="external-link">fpiter</a></code> or
  <code><a href="https://rdrr.io/pkg/daarem/man/daarem.html" class="external-link">daarem</a></code>. In brief, it sets the upper limit on
  the number of CCD updates.</p></dd>


<dt><code>convtype</code></dt>
<dd><p>This is the value of the “convtype”
  control argument for <code><a href="https://rdrr.io/pkg/daarem/man/daarem.html" class="external-link">daarem</a></code>. It determines
  whether the stopping criterion is based on the change in the
  estimates or the change in the log-likelihood between two
  successive updates.</p></dd>


<dt><code>mon.tol</code></dt>
<dd><p>This is the value of the “mon.tol”
  control argument for <code><a href="https://rdrr.io/pkg/daarem/man/daarem.html" class="external-link">daarem</a></code>. This setting
  determines to what extent the monotonicity condition can be
  violated.</p></dd>


<dt><code>num_ccd_iter</code></dt>
<dd><p>Number of co-ordinate descent updates to
  be made to parameters at each iteration of the algorithm.</p></dd>


<dt><code>line_search</code></dt>
<dd><p>If <code>line_search = TRUE</code>, a
  backtracking line search is performed at each iteration of CCD to
  guarantee improvement in the objective (the log-likelihood).</p></dd>


<dt><code>ls_alpha</code></dt>
<dd><p>alpha parameter for backtracking line search.
  (Should be a number between 0 and 0.5, typically a number near
  zero.)</p></dd>


<dt><code>ls_beta</code></dt>
<dd><p>beta parameter for backtracking line search
  controlling the rate at which the step size is decreased.
  (Should be a number between 0 and 0.5.)</p></dd>


<dt><code>calc_deriv</code></dt>
<dd><p>If <code>calc_deriv = TRUE</code>, the maximum
  gradient of \(U\) and \(V\) is calculated and stored after each
  update. This may be useful for assessing convergence of the
  optimization, though increases overhead.</p></dd>


<dt><code>calc_max_diff</code></dt>
<dd><p>If <code>calc_max_diff = TRUE</code>, the
  largest change in \(U\) and \(V\) after each update is
  calculated and stored. This may be useful for monitoring progress
  of the optimization algorithm.</p></dd>


<dt><code>orthonormalize</code></dt>
<dd><p>If <code>orthonormalize = TRUE</code>, the
  matrices \(U\) and \(V\) are made to be orthogonal after each
  update step. This improves the speed of convergence without the
  DAAREM acceleration; however, should not be used when
  <code>use_daarem = TRUE</code>.</p></dd>

</dl><p>You may use function <code><a href="set_fastglmpca_threads.html">set_fastglmpca_threads</a></code> to adjust
the number of threads used in performing the updates.</p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Townes, F. W., Hicks, S. C., Aryee, M. J. and Irizarry,
  R. A. (2019). Feature selection and dimension reduction for
  single-cell RNA-Seq based on a multinomial model. <em>Genome Biology</em>
  <b>20</b>, 295. <a href="https://doi.org/10.1186/s13059-019-1861-6" class="external-link">doi:10.1186/s13059-019-1861-6</a></p>
<p>Collins, M., Dasgupta, S. and Schapire, R. E. (2002). A
  generalization of principal components analysis to the exponential
  family. In <em>Advances in Neural Information Processing Systems</em> 14.</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code>fit_glmpca_pois</code></p></div>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">200</span></span></span>
<span class="r-in"><span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">100</span></span></span>
<span class="r-in"><span><span class="va">K</span> <span class="op">&lt;-</span> <span class="fl">3</span></span></span>
<span class="r-in"><span><span class="va">dat</span>  <span class="op">&lt;-</span> <span class="fu"><a href="generate_glmpca_data_pois.html">generate_glmpca_data_pois</a></span><span class="op">(</span><span class="va">n</span>,<span class="va">p</span>,<span class="va">K</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">fit0</span> <span class="op">&lt;-</span> <span class="fu">init_glmpca_pois</span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Y</span>,<span class="va">K</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">fit</span>  <span class="op">&lt;-</span> <span class="fu">fit_glmpca_pois</span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">Y</span>,fit0 <span class="op">=</span> <span class="va">fit0</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Fitting GLM-PCA model to 200 x 100 count matrix.</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 1: log-likelihood = -9.150188547370e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 2: log-likelihood = -4.053287865351e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 3: log-likelihood = -3.613824011415e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 4: log-likelihood = -3.544135095378e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 5: log-likelihood = -3.524332761304e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 6: log-likelihood = -3.516524199745e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 7: log-likelihood = -3.512755108135e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 8: log-likelihood = -3.510690088392e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 9: log-likelihood = -3.509464345815e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 10: log-likelihood = -3.508696785545e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 11: log-likelihood = -3.508196851573e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 12: log-likelihood = -3.507860615708e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 13: log-likelihood = -3.507627979214e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 14: log-likelihood = -3.507462749014e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 15: log-likelihood = -3.507342462213e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 16: log-likelihood = -3.507252834177e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 17: log-likelihood = -3.507184585954e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 18: log-likelihood = -3.507131570026e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 19: log-likelihood = -3.507089635393e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 20: log-likelihood = -3.507055926109e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 21: log-likelihood = -3.507028440341e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 22: log-likelihood = -3.507005748682e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 23: log-likelihood = -3.506986811658e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 24: log-likelihood = -3.506970859857e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 25: log-likelihood = -3.506957313873e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 26: log-likelihood = -3.506945730176e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 27: log-likelihood = -3.506935764094e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 28: log-likelihood = -3.506927144065e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 29: log-likelihood = -3.506919653339e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 30: log-likelihood = -3.506913116934e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 31: log-likelihood = -3.506907392091e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 32: log-likelihood = -3.506902361308e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 33: log-likelihood = -3.506897927068e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 34: log-likelihood = -3.506894007835e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 35: log-likelihood = -3.506890535058e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 36: log-likelihood = -3.506887450650e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 37: log-likelihood = -3.506884705228e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 38: log-likelihood = -3.506882256615e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 39: log-likelihood = -3.506880068601e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 40: log-likelihood = -3.506878109978e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 41: log-likelihood = -3.506876353786e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 42: log-likelihood = -3.506874776663e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 43: log-likelihood = -3.506873358261e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 44: log-likelihood = -3.506872080834e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 45: log-likelihood = -3.506870928857e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 46: log-likelihood = -3.506869888712e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 47: log-likelihood = -3.506868948441e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 48: log-likelihood = -3.506868097488e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 49: log-likelihood = -3.506867326566e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 50: log-likelihood = -3.506866627429e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 51: log-likelihood = -3.506865992786e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 52: log-likelihood = -3.506865416168e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 53: log-likelihood = -3.506864891821e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 54: log-likelihood = -3.506864414612e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 55: log-likelihood = -3.506863979961e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 56: log-likelihood = -3.506863583749e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 57: log-likelihood = -3.506863222343e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 58: log-likelihood = -3.506862892469e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 59: log-likelihood = -3.506862591170e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 60: log-likelihood = -3.506862315804e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 61: log-likelihood = -3.506862063999e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 62: log-likelihood = -3.506861833595e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 63: log-likelihood = -3.506861622658e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 64: log-likelihood = -3.506861429453e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 65: log-likelihood = -3.506861252396e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 66: log-likelihood = -3.506861090065e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 67: log-likelihood = -3.506860941160e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 68: log-likelihood = -3.506860804513e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 69: log-likelihood = -3.506860679059e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 70: log-likelihood = -3.506860563833e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 71: log-likelihood = -3.506860457963e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 72: log-likelihood = -3.506860360654e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 73: log-likelihood = -3.506860271175e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 74: log-likelihood = -3.506860188870e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 75: log-likelihood = -3.506860113136e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 76: log-likelihood = -3.506860043428e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 77: log-likelihood = -3.506859979246e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 78: log-likelihood = -3.506859920134e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 79: log-likelihood = -3.506859865677e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 80: log-likelihood = -3.506859815491e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 81: log-likelihood = -3.506859769230e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 82: log-likelihood = -3.506859726579e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 83: log-likelihood = -3.506859687240e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 84: log-likelihood = -3.506859650954e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 85: log-likelihood = -3.506859617475e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 86: log-likelihood = -3.506859586570e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 87: log-likelihood = -3.506859558047e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 88: log-likelihood = -3.506859531707e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 89: log-likelihood = -3.506859507379e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 90: log-likelihood = -3.506859484907e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 91: log-likelihood = -3.506859464145e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 92: log-likelihood = -3.506859444962e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 93: log-likelihood = -3.506859427229e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 94: log-likelihood = -3.506859410832e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 95: log-likelihood = -3.506859395670e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 96: log-likelihood = -3.506859381645e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 97: log-likelihood = -3.506859368671e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 98: log-likelihood = -3.506859356667e+04</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Iteration 99: log-likelihood = -3.506859345558e+04</span>
<span class="r-wrn co"><span class="r-pr">#&gt;</span> <span class="warning">Warning: </span>fit_glmpca_pois failed to meet convergence criterion within 100 iterations</span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Eric Weine, Peter Carbonetto, Matthew Stephens.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer></div>

  


  

  </body></html>

