% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit.R
\name{fit_glmpca_pois}
\alias{fit_glmpca_pois}
\title{Fit GLM-PCA Model to Count Data}
\usage{
fit_glmpca_pois(
  Y,
  K,
  fit0,
  tol = 1e-04,
  min_iter = 1,
  max_iter = 100,
  verbose = TRUE,
  control = list()
)
}
\arguments{
\item{Y}{The n x p matrix of counts; all entries of Y should be
non-negative. Y may be a sparse matrix from the \code{Matrix}
package.}

\item{K}{An integer 1 or greater giving the matrix rank. This
argument will be ignored if the initial fit
(\code{fit0}) is provided.}

\item{fit0}{The initial model fit. It should be an object of class
\dQuote{glmpca_fit}, such as an output from \code{init_glmpca}, 
or from a previous call to \code{fit_glmpca}.}

\item{tol}{Positive scalar determining relative tolerance for assessing convergence.
Convergence is determined by comparing the log-likelihood at the previous
iteration to the current iteration.}

\item{min_iter}{Minimum number of updates to \eqn{L} and \eqn{F} to be run.}

\item{max_iter}{Maximum number of updates to \eqn{L} and \eqn{F} to be run.}

\item{verbose}{Boolean indicating if likelihood should be printed at each step.}

\item{control}{List of control parameters to modify behavior of \code{algorithm}.}
}
\value{
An object capturing the final state of the model fit. It will contain
the final values of \eqn{L} and \eqn{F}, as well as a dataframe \code{progress}
that records information about the algorithm progress at each iteration.
}
\description{
Fit a GLM-PCA model to input matrix \code{Y}
  by maximum likelihood.
}
\details{
In generalized principal component analysis (GLM-PCA)
based on a Poisson likelihood (Townes et al, 2019), the counts
\eqn{y_{ij}} in the n x p matrix \eqn{Y} are modeled as
\deqn{y_{ij} \sim Poisson(\lambda_{ij}).} The logarithm of each
Poisson rate is defined as a linear combination of the parameters:
\deqn{\log \lambda_{ij} = \sum_{k=1}^K l_{ki} f_{kj} = (L'F)_{ij}.} The model
parameters are stored as an K x n matrix \eqn{L} with entries
\eqn{l_{ki}} and an K x p matrix \eqn{F} with entries \eqn{f_{kj}}.
\eqn{K} is a tuning parameter specifying the rank of the matrices
\eqn{L} and \eqn{F}. \code{fit_glmpca_pois} computes maximum-likelihood
estimates (MLEs) of \eqn{L} and \eqn{F}.

The algorithm works by repeatedly alternating between updating \eqn{L} with
\eqn{F} fixed and updating \eqn{F} with \eqn{L} fixed. Each update takes
the form of a series of Poisson regressions solved using cyclic co-ordinate
descent (ccd).

The \code{control} argument is a list in which any of the following
named components will override the default optimization algorithm
settings (as they are defined by \code{fit_glmpca_control_default}):

\describe{

\item{\code{num_iter}}{Number of ccd updates to be made to parameters
  at each iteration of the algorithm.}

\item{\code{line_search}}{Boolean indicating if backtracking line search
  should be performed at each ccd iteration.}

\item{\code{alpha}}{alpha value of line search between 0 and .5.}

\item{\code{beta}}{beta value of line search between 0 and .5.}
  
\item{\code{calc_deriv}}{boolean indicated if maximum absolute derivatives of
 \eqn{L} and \eqn{F} should be calculated at each step of optimization. This may
 be useful for monitoring convergence though may have substantial computational
 cost for large matrices.}
  
\item{\code{calc_max_diff}}{boolean indicating if maximum absolute difference 
between successive updates of \eqn{L} and \eqn{F} should be calulcated and
stored. This may be useful for monitoring convergence.}
  
}
}
\examples{
set.seed(1)

n <- 1000
p <- 500
K <- 1

data <- generate_glmpca_data_pois(n, p, K)
# initialize fit
fit0 <- init_glmpca_pois(
  Y = data$Y, 
  K = K,
  fit_col_size_factor = TRUE, 
  fit_row_intercept = TRUE
)

fit <- fit_glmpca_pois(Y = data$Y, fit0 = fit0)

}
\references{
Townes, F. W., Hicks, S. C., Aryee, M. J. and Irizarry,
R. A. (2019). Feature selection and dimension reduction for
single-cell RNA-Seq based on a multinomial model. \emph{Genome Biology}
\bold{20}, 295. \url{https://doi.org/10.1186/s13059-019-1861-6}

Collins, M., Dasgupta, S. and Schapire, R. E. (2002). A
generalization of principal components analysis to the exponential
family. In \emph{Advances in Neural Information Processing Systems} 14.
}
